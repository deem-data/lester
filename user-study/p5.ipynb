{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPYYmf6g9nXI",
    "outputId": "c8071f6d-065f-4fdd-c5b5-c09e0c84896a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-13.11.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▏                               | 10 kB 18.6 MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 20 kB 23.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 30 kB 25.0 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 40 kB 16.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 51 kB 9.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 61 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 71 kB 8.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 81 kB 9.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 92 kB 10.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 102 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 112 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 122 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 133 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 143 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 153 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 163 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 174 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 184 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 194 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 204 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 215 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 225 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 235 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 245 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 256 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 266 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 276 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 286 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 296 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 307 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 317 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 327 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 337 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 348 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 358 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 368 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 378 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 389 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 399 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 409 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 419 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 430 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 440 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 450 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 460 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 471 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 481 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 491 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 501 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 512 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 522 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 532 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 542 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 552 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 563 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 573 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 583 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 593 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 604 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 614 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 624 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 634 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 645 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 655 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 665 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 675 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 686 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 696 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 706 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 716 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 727 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 737 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 747 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 757 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 768 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 778 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 788 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 798 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 808 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 819 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 829 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 839 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 849 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 860 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 870 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 880 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 890 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 901 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 911 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 921 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 931 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 942 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 952 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 962 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 972 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 983 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 993 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 1.0 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.0 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 1.0 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 1.0 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 1.0 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 1.1 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.2 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 1.3 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 1.3 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.3 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 1.3 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.3 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.3 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.3 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.3 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.3 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.4 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.5 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.5 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.5 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.5 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.5 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.5 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 1.5 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 1.5 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.5 MB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.5 MB 10.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.2 in /usr/local/lib/python3.7/dist-packages (from faker) (4.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.4->faker) (1.15.0)\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-13.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ilXTZZ4K8JgR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder, label_binarize, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "B2KkAyfKJVcO"
   },
   "outputs": [],
   "source": [
    "#added by Kasper Lindhorst as part of the user case study\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nJmIwT0a805d"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "  print(\"  Data access - Loading all four input relations from github\")\n",
    "\n",
    "  base_url = 'https://github.com/schelterlabs/arguseyes/raw/freamon/arguseyes/example_pipelines/datasets/freamon'  \n",
    "\n",
    "  reviews = pd.read_csv(f'{base_url}/reviews.csv.gz', compression='gzip', index_col=0)\n",
    "  ratings = pd.read_csv(f'{base_url}/ratings.csv', index_col=0)\n",
    "  products = pd.read_csv(f'{base_url}/products.csv', index_col=0)\n",
    "  categories = pd.read_csv(f'{base_url}/categories.csv', index_col=0)\n",
    "\n",
    "  return reviews, ratings, products, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GQ19UKmB93dh"
   },
   "outputs": [],
   "source": [
    "def random_subset(arr):\n",
    "  size = np.random.randint(low=1, high=len(arr)+1)\n",
    "  choice = np.random.choice(arr, size=size, replace=False)\n",
    "  return [str(item) for item in choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hbEgdmQZ9fqS"
   },
   "outputs": [],
   "source": [
    "def integrate_data(reviews, ratings, products, categories, fake):\n",
    "  start_date = fake.date_between(start_date=datetime.date(year=2011, month=1, day=1),\n",
    "                                  end_date=datetime.date(year=2013, month=6, day=1))\n",
    "\n",
    "  print(f\"  Data Integration - Dropping reviews written before {start_date.strftime('%Y-%m-%d')}\")\n",
    "  reviews = reviews[reviews.review_date >= start_date.strftime('%Y-%m-%d')]\n",
    "\n",
    "  reviews_with_ratings = reviews.merge(ratings, on='review_id')\n",
    "  products_with_categories = products.merge(left_on='category_id', right_on='id', right=categories)\n",
    "\n",
    "  random_categories = random_subset(list(categories.category))\n",
    "  print(f\"  Data Integration - restricting products to the following categories {random_categories}\")\n",
    "  products_with_categories = products_with_categories[products_with_categories.category.isin(random_categories)]\n",
    "\n",
    "  reviews_with_products_and_ratings = reviews_with_ratings.merge(products_with_categories, on='product_id')\n",
    "\n",
    "  print(f\"  Data Integration - joined reviews, ratings, products & categories\")\n",
    "  return reviews_with_products_and_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eK-YXgMH9wpi"
   },
   "outputs": [],
   "source": [
    "def compute_feature_and_label_data(reviews_with_products_and_ratings, final_columns, fake):\n",
    "  reviews_with_products_and_ratings['product_title'] = \\\n",
    "      reviews_with_products_and_ratings['product_title'].fillna(value='')\n",
    "\n",
    "  reviews_with_products_and_ratings['review_headline'] = \\\n",
    "      reviews_with_products_and_ratings['review_headline'].fillna(value='')\n",
    "\n",
    "  reviews_with_products_and_ratings['review_body'] = \\\n",
    "      reviews_with_products_and_ratings['review_body'].fillna(value='')\n",
    "\n",
    "  num_text_columns = np.random.randint(low=1, high=4)\n",
    "  random_text_columns = np.random.choice(['product_title', 'review_headline', 'review_body'],\n",
    "                                          size=num_text_columns, replace=False)\n",
    "\n",
    "  print(f\"  Data preparation - using columns {random_text_columns} as textual feature \")\n",
    "  reviews_with_products_and_ratings['text'] = ' '\n",
    "  for text_column in random_text_columns:\n",
    "      reviews_with_products_and_ratings['text'] = reviews_with_products_and_ratings['text'] + ' ' \\\n",
    "                                                  + reviews_with_products_and_ratings[text_column]\n",
    "\n",
    "  reviews_with_products_and_ratings['is_helpful'] = reviews_with_products_and_ratings['helpful_votes'] > 0\n",
    "\n",
    "  print(f\"  Projecting data to the feature and label columns {final_columns}\")\n",
    "  projected_reviews = reviews_with_products_and_ratings[final_columns]\n",
    "\n",
    "  split_date = fake.date_between(start_date=datetime.date(year=2013, month=12, day=1),\n",
    "                                  end_date=datetime.date(year=2015, month=1, day=1))\n",
    "\n",
    "  print(f\"  Data preparation - temporal train/test split based on date {split_date}\")\n",
    "  train_data = projected_reviews[projected_reviews.review_date <= split_date.strftime('%Y-%m-%d')]\n",
    "  train_labels = label_binarize(train_data['is_helpful'], classes=[True, False]).ravel()\n",
    "\n",
    "  test_data = projected_reviews[projected_reviews.review_date > split_date.strftime('%Y-%m-%d')]\n",
    "  test_labels = label_binarize(test_data['is_helpful'], classes=[True, False]).ravel()\n",
    "\n",
    "  return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NH_bep9J-Imh"
   },
   "outputs": [],
   "source": [
    "def define_model(numerical_columns, categorical_columns):\n",
    "  print(f\"  Feature encoding - Setting up feature transformations\")\n",
    "  feature_transformation = ColumnTransformer(transformers=[\n",
    "    ('numerical_features', StandardScaler(), numerical_columns),\n",
    "    ('categorical_features', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "    ('textual_features', HashingVectorizer(ngram_range=(1, 3), n_features=100), 'text'),\n",
    "  ], remainder=\"drop\")\n",
    "\n",
    "  print(f\"  Modeling - defining a logistic regression model\")\n",
    "  sklearn_model = Pipeline([\n",
    "    ('features', feature_transformation),\n",
    "    ('learner', SGDClassifier(loss='log', penalty='l1', max_iter=1000))])\n",
    "\n",
    "  return sklearn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Fw-y6bKB-bz"
   },
   "source": [
    "\n",
    "### Task 1 - Group Fairness\n",
    "\n",
    "__Compute the fairness of the pipeline with respect to third party reviews__. In particular, compute the [equal opportunity](https://en.wikipedia.org/wiki/Fairness_(machine_learning)#Group_Fairness_criteria) metric (the difference in false negative rates) between reviews from a third party and reviews not from a third party.\n",
    "\n",
    "### Task 2 - Data Usage\n",
    "\n",
    "__Compute which records from the ratings and products relation are used to train the classifier__. Compute two boolean arrays with a dimensionality similar to the cardinality of the relations, where the entry at position i denotes whether the i-th record is included in the training data of the classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nbbZc5qk-Qnr"
   },
   "outputs": [],
   "source": [
    "def execute_pipeline(seed):\n",
    "  fake = Faker()\n",
    "  fake.seed_instance(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  print('---------------------------------------------------------------------')\n",
    "  print(f'Executing pipeline with seed {seed}')\n",
    "  print('---------------------------------------------------------------------')\n",
    "\n",
    "  numerical_columns = random_subset(['total_votes', 'star_rating'])\n",
    "  categorical_columns = random_subset(['customer_id', 'product_id', 'vine', 'category'])\n",
    "  final_columns = numerical_columns + categorical_columns + ['text', 'is_helpful', 'review_date']\n",
    "\n",
    "  reviews, ratings, products, categories = load_data()\n",
    "\n",
    "  integrated_data = integrate_data(reviews, ratings, products, categories, fake)\n",
    "  train_data, train_labels, test_data, test_labels = \\\n",
    "      compute_feature_and_label_data(integrated_data, final_columns, fake)\n",
    "\n",
    "  sklearn_model = define_model(numerical_columns, categorical_columns)\n",
    "\n",
    "  model = sklearn_model.fit(train_data, train_labels)\n",
    "\n",
    "  # TODO these must be computed by you\n",
    "  # def perf_measure(y_actual, y_hat):\n",
    "  #   TP = 0\n",
    "  #   FP = 0\n",
    "  #   TN = 0\n",
    "  #   FN = 0\n",
    "\n",
    "  #   for i in range(len(y_hat)): \n",
    "  #       if integrated_data[reviews]==integrated_data[reviews]==1:\n",
    "  #          TP += 1\n",
    "  #       if integrated_data[reviews]==1 and integrated_data[reviews]!= integrated_data[reviews]:\n",
    "  #          FP += 1\n",
    "  #       if integrated_data[reviews]==integrated_data[reviews]==0:\n",
    "  #          TN += 1\n",
    "  #       if integrated_data[reviews]==0 and integrated_data[reviews]!=integrated_data[reviews]:\n",
    "  #          FN += 1\n",
    "\n",
    "  #   return(TP, FP, TN, FN)\n",
    "\n",
    "  tpr = recall_score(reviews, ratings)\n",
    "  tnr = recall_score(reviews, ratings, pos_label = 0) \n",
    "  fpr = 1 - tnr\n",
    "  fnr = 1 - tpr\n",
    "\n",
    "  equal_opportunity = fnr\n",
    "  ratings_usage = np.full(len(ratings), False)\n",
    "  products_usage = np.full(len(products), False)\n",
    "\n",
    "  print('---------------------------------------------------------------------')\n",
    "  print('Train accuracy', model.score(train_data, train_labels))\n",
    "  print('Test accuracy', model.score(test_data, test_labels))\n",
    "  print(f'Equal opportunity w.r.t. third party reviews {equal_opportunity}')\n",
    "  print(f'# Number of ratings used {np.sum(ratings_usage)}')\n",
    "  print(f'# Number of products used {np.sum(products_usage)}')\n",
    "  print('---------------------------------------------------------------------\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "ytf_9imO-cX-",
    "outputId": "43c9ca6d-d90a-4daa-d9af-48a1d24c556b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "Executing pipeline with seed 1234\n",
      "---------------------------------------------------------------------\n",
      "  Data access - Loading all four input relations from github\n",
      "  Data Integration - Dropping reviews written before 2012-11-15\n",
      "  Data Integration - restricting products to the following categories ['Digital_Video_Games']\n",
      "  Data Integration - joined reviews, ratings, products & categories\n",
      "  Data preparation - using columns ['review_body' 'product_title'] as textual feature \n",
      "  Projecting data to the feature and label columns ['total_votes', 'star_rating', 'category', 'vine', 'customer_id', 'text', 'is_helpful', 'review_date']\n",
      "  Data preparation - temporal train/test split based on date 2014-03-01\n",
      "  Feature encoding - Setting up feature transformations\n",
      "  Modeling - defining a logistic regression model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-29adafbc88ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseeds_to_evaluate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5678\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m91011\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m121314\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m151617\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds_to_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-6374b58ffa54>\u001b[0m in \u001b[0;36mexecute_pipeline\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m#   return(TP, FP, TN, FN)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0mtpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0mtnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mfpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtnr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m     )\n\u001b[1;32m   1911\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [246560, 100000]"
     ]
    }
   ],
   "source": [
    "seeds_to_evaluate = [1234, 5678, 91011, 121314, 151617]\n",
    "for seed in seeds_to_evaluate:\n",
    "  execute_pipeline(seed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Kasper-freamon-user-study.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
