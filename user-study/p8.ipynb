{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3913,
     "status": "ok",
     "timestamp": 1652879711069,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "TPYYmf6g9nXI",
    "outputId": "811e50b3-a260-4929-bd2d-6a082d75a2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /usr/local/lib/python3.7/dist-packages (13.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.2 in /usr/local/lib/python3.7/dist-packages (from faker) (4.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.4->faker) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1566,
     "status": "ok",
     "timestamp": 1652879712632,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "ilXTZZ4K8JgR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder, label_binarize, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652879712633,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "nJmIwT0a805d"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "  print(\"  Data access - Loading all four input relations from github\")\n",
    "\n",
    "  base_url = 'https://github.com/schelterlabs/arguseyes/raw/freamon/arguseyes/example_pipelines/datasets/freamon'  \n",
    "\n",
    "  reviews = pd.read_csv(f'{base_url}/reviews.csv.gz', compression='gzip', index_col=0)\n",
    "  ratings = pd.read_csv(f'{base_url}/ratings.csv', index_col=0)\n",
    "  products = pd.read_csv(f'{base_url}/products.csv', index_col=0)\n",
    "  categories = pd.read_csv(f'{base_url}/categories.csv', index_col=0)\n",
    "\n",
    "  return reviews, ratings, products, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652879712633,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "GQ19UKmB93dh"
   },
   "outputs": [],
   "source": [
    "def random_subset(arr):\n",
    "  size = np.random.randint(low=1, high=len(arr)+1)\n",
    "  choice = np.random.choice(arr, size=size, replace=False)\n",
    "  return [str(item) for item in choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652879712633,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "hbEgdmQZ9fqS"
   },
   "outputs": [],
   "source": [
    "def integrate_data(reviews, ratings, products, categories, fake):\n",
    "  start_date = fake.date_between(start_date=datetime.date(year=2011, month=1, day=1),\n",
    "                                  end_date=datetime.date(year=2013, month=6, day=1))\n",
    "\n",
    "  print(f\"  Data Integration - Dropping reviews written before {start_date.strftime('%Y-%m-%d')}\")\n",
    "  reviews = reviews[reviews.review_date >= start_date.strftime('%Y-%m-%d')]\n",
    "\n",
    "  reviews_with_ratings = reviews.merge(ratings, on='review_id')\n",
    "  products_with_categories = products.merge(left_on='category_id', right_on='id', right=categories)\n",
    "\n",
    "  random_categories = random_subset(list(categories.category))\n",
    "  print(f\"  Data Integration - restricting products to the following categories {random_categories}\")\n",
    "  products_with_categories = products_with_categories[products_with_categories.category.isin(random_categories)]\n",
    "\n",
    "  reviews_with_products_and_ratings = reviews_with_ratings.merge(products_with_categories, on='product_id')\n",
    "\n",
    "  print(f\"  Data Integration - joined reviews, ratings, products & categories\")\n",
    "  return reviews_with_products_and_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652879712634,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "eK-YXgMH9wpi"
   },
   "outputs": [],
   "source": [
    "def compute_feature_and_label_data(reviews_with_products_and_ratings, final_columns, fake):\n",
    "  reviews_with_products_and_ratings['product_title'] = \\\n",
    "      reviews_with_products_and_ratings['product_title'].fillna(value='')\n",
    "\n",
    "  reviews_with_products_and_ratings['review_headline'] = \\\n",
    "      reviews_with_products_and_ratings['review_headline'].fillna(value='')\n",
    "\n",
    "  reviews_with_products_and_ratings['review_body'] = \\\n",
    "      reviews_with_products_and_ratings['review_body'].fillna(value='')\n",
    "\n",
    "  num_text_columns = np.random.randint(low=1, high=4)\n",
    "  random_text_columns = np.random.choice(['product_title', 'review_headline', 'review_body'],\n",
    "                                          size=num_text_columns, replace=False)\n",
    "\n",
    "  print(f\"  Data preparation - using columns {random_text_columns} as textual feature \")\n",
    "  reviews_with_products_and_ratings['text'] = ' '\n",
    "  for text_column in random_text_columns:\n",
    "      reviews_with_products_and_ratings['text'] = reviews_with_products_and_ratings['text'] + ' ' \\\n",
    "                                                  + reviews_with_products_and_ratings[text_column]\n",
    "\n",
    "  reviews_with_products_and_ratings['is_helpful'] = reviews_with_products_and_ratings['helpful_votes'] > 0\n",
    "\n",
    "  print(f\"  Projecting data to the feature and label columns {final_columns}\")\n",
    "  third_party = reviews_with_products_and_ratings[\"third_party\"]  # Added \n",
    "  review_id = reviews_with_products_and_ratings[\"review_id\"]  # Added\n",
    "  product_id = reviews_with_products_and_ratings[\"product_id\"]  # Added\n",
    "  projected_reviews = reviews_with_products_and_ratings[final_columns]\n",
    "\n",
    "  split_date = fake.date_between(start_date=datetime.date(year=2013, month=12, day=1),\n",
    "                                  end_date=datetime.date(year=2015, month=1, day=1))\n",
    "\n",
    "  print(f\"  Data preparation - temporal train/test split based on date {split_date}\")\n",
    "  train_filter = projected_reviews.review_date <= split_date.strftime('%Y-%m-%d')  # Refactored\n",
    "  train_data = projected_reviews[train_filter]\n",
    "  train_labels = label_binarize(train_data['is_helpful'], classes=[True, False]).ravel()\n",
    "  train_fairness_filter = third_party[train_filter]  # Added\n",
    "  train_review_id = review_id[train_filter]  # Added\n",
    "  train_product_id = product_id[train_filter]  # Added\n",
    "\n",
    "  test_filter = projected_reviews.review_date > split_date.strftime('%Y-%m-%d')  # Refactored\n",
    "  test_data = projected_reviews[test_filter]\n",
    "  test_labels = label_binarize(test_data['is_helpful'], classes=[True, False]).ravel()\n",
    "  test_fairness_filter = third_party[test_filter]  # Added\n",
    "  test_review_id = review_id[test_filter]  # Added\n",
    "  test_product_id = product_id[test_filter]  # Added\n",
    "\n",
    "  return train_data, train_labels, train_fairness_filter, train_review_id, train_product_id, test_data, test_labels, test_fairness_filter, test_review_id, test_product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652879712634,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "NH_bep9J-Imh"
   },
   "outputs": [],
   "source": [
    "def define_model(numerical_columns, categorical_columns):\n",
    "  print(f\"  Feature encoding - Setting up feature transformations\")\n",
    "  feature_transformation = ColumnTransformer(transformers=[\n",
    "    ('numerical_features', StandardScaler(), numerical_columns),\n",
    "    ('categorical_features', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "    ('textual_features', HashingVectorizer(ngram_range=(1, 3), n_features=100), 'text'),\n",
    "  ], remainder=\"drop\")\n",
    "\n",
    "  print(f\"  Modeling - defining a logistic regression model\")\n",
    "  sklearn_model = Pipeline([\n",
    "    ('features', feature_transformation),\n",
    "    ('learner', SGDClassifier(loss='log', penalty='l1', max_iter=1000))])\n",
    "\n",
    "  return sklearn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Fw-y6bKB-bz"
   },
   "source": [
    "\n",
    "### Task 1 - Group Fairness\n",
    "\n",
    "__Compute the fairness of the pipeline with respect to third party reviews__. In particular, compute the [equal opportunity](https://en.wikipedia.org/wiki/Fairness_(machine_learning)#Group_Fairness_criteria) metric (the difference in false negative rates) between reviews from a third party and reviews not from a third party.\n",
    "\n",
    "### Task 2 - Data Usage\n",
    "\n",
    "__Compute which records from the ratings and products relation are used to train the classifier__. Compute two boolean arrays with a dimensionality similar to the cardinality of the relations, where the entry at position i denotes whether the i-th record is included in the training data of the classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652879712635,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "CeMTHoGWGhBB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_fnr(target, pred):\n",
    "  tn, fp, fn, tp = confusion_matrix(target, pred, labels=[0,1]).ravel()\n",
    "  p = tp + fn\n",
    "  fnr = fn / p if p > 0.0 else np.float64(0.0)\n",
    "\n",
    "\n",
    "def calculate_equal_opportunity(model, X, y, fairness_filter):\n",
    "  pred = model.predict(X)\n",
    "\n",
    "  # Separate pred and target into two groups based on third party reviews\n",
    "  pred1, pred2 = [], []\n",
    "  target1, target2 = [], []\n",
    "  for idx in range(len(pred)):\n",
    "    if fairness_filter[idx]:\n",
    "      pred1.append(pred[idx])\n",
    "      target1.append(y[idx])\n",
    "    else:\n",
    "      pred2.append(pred[idx])\n",
    "      target2.append(y[idx])\n",
    "\n",
    "  # Calculate FNR for two subgroups\n",
    "  fnr1 = calculate_fnr(target1, pred1)\n",
    "  fnr2 = calculate_fnr(target2, pred2)\n",
    "\n",
    "  # Calculate difference in FNR\n",
    "  fnr_diff = fnr1 - fnr2\n",
    "\n",
    "  return abs(fnr_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1652880110380,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "nbbZc5qk-Qnr"
   },
   "outputs": [],
   "source": [
    "def execute_pipeline(seed):\n",
    "  fake = Faker()\n",
    "  fake.seed_instance(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  print('---------------------------------------------------------------------')\n",
    "  print(f'Executing pipeline with seed {seed}')\n",
    "  print('---------------------------------------------------------------------')\n",
    "\n",
    "  numerical_columns = random_subset(['total_votes', 'star_rating'])\n",
    "  categorical_columns = random_subset(['customer_id', 'product_id', 'vine', 'category'])\n",
    "  final_columns = numerical_columns + categorical_columns + ['text', 'is_helpful', 'review_date']\n",
    "\n",
    "  reviews, ratings, products, categories = load_data()\n",
    "\n",
    "  integrated_data = integrate_data(reviews, ratings, products, categories, fake)\n",
    "  train_data, train_labels, train_fairness_filter, train_review_id, train_product_id, \\\n",
    "    test_data, test_labels, test_fairness_filter, test_review_id, test_product_id = \\\n",
    "      compute_feature_and_label_data(integrated_data, final_columns, fake)\n",
    "\n",
    "  sklearn_model = define_model(numerical_columns, categorical_columns)\n",
    "\n",
    "  model = sklearn_model.fit(train_data, train_labels)\n",
    "\n",
    "  # TODO these must be computed by you\n",
    "  equal_opportunity = 0.0  # calculate_equal_opportunity(model, train_data, train_labels, train_fairness_filter)\n",
    "  \n",
    "  ratings_usage = ratings[\"review_id\"].isin(train_review_id)\n",
    "  products_usage = products[\"product_id\"].isin(train_product_id)\n",
    "\n",
    "  print('---------------------------------------------------------------------')\n",
    "  print('Train accuracy', model.score(train_data, train_labels))\n",
    "  print('Test accuracy', model.score(test_data, test_labels))\n",
    "  print(f'Equal opportunity w.r.t. third party reviews {equal_opportunity}')\n",
    "  print(f'# Number of ratings used {np.sum(ratings_usage)}')\n",
    "  print(f'# Number of products used {np.sum(products_usage)}')\n",
    "  print('---------------------------------------------------------------------\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "Executing pipeline with seed 1234\n",
      "---------------------------------------------------------------------\n",
      "  Data access - Loading all four input relations from github\n",
      "  Data Integration - Dropping reviews written before 2012-11-15\n",
      "  Data Integration - restricting products to the following categories ['Digital_Video_Games']\n",
      "  Data Integration - joined reviews, ratings, products & categories\n",
      "  Data preparation - using columns ['review_body' 'product_title'] as textual feature \n",
      "  Projecting data to the feature and label columns ['total_votes', 'star_rating', 'category', 'vine', 'customer_id', 'text', 'is_helpful', 'review_date']\n",
      "  Data preparation - temporal train/test split based on date 2014-03-01\n",
      "  Feature encoding - Setting up feature transformations\n",
      "  Modeling - defining a logistic regression model\n",
      "---------------------------------------------------------------------\n",
      "Train accuracy 0.8447098976109215\n",
      "Test accuracy 0.8784434598343287\n",
      "Equal opportunity w.r.t. third party reviews 0.0\n",
      "# Number of ratings used 23440\n",
      "# Number of products used 3088\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_pipeline(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100329,
     "status": "ok",
     "timestamp": 1652880211013,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "ytf_9imO-cX-",
    "outputId": "98f13a59-bee0-4fa5-e939-2c23718e6eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "Executing pipeline with seed 1234\n",
      "---------------------------------------------------------------------\n",
      "  Data access - Loading all four input relations from github\n",
      "  Data Integration - Dropping reviews written before 2012-11-15\n",
      "  Data Integration - restricting products to the following categories ['Digital_Video_Games']\n",
      "  Data Integration - joined reviews, ratings, products & categories\n",
      "  Data preparation - using columns ['review_body' 'product_title'] as textual feature \n",
      "  Projecting data to the feature and label columns ['total_votes', 'star_rating', 'category', 'vine', 'customer_id', 'text', 'is_helpful', 'review_date']\n",
      "  Data preparation - temporal train/test split based on date 2014-03-01\n",
      "  Feature encoding - Setting up feature transformations\n",
      "  Modeling - defining a logistic regression model\n",
      "---------------------------------------------------------------------\n",
      "Train accuracy 0.8447098976109215\n",
      "Test accuracy 0.8784434598343287\n",
      "Equal opportunity w.r.t. third party reviews 0.0\n",
      "# Number of ratings used 23440\n",
      "# Number of products used 3088\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Executing pipeline with seed 5678\n",
      "---------------------------------------------------------------------\n",
      "  Data access - Loading all four input relations from github\n",
      "  Data Integration - Dropping reviews written before 2011-12-15\n",
      "  Data Integration - restricting products to the following categories ['Digital_Software', 'Digital_Video_Games']\n",
      "  Data Integration - joined reviews, ratings, products & categories\n",
      "  Data preparation - using columns ['review_headline' 'product_title' 'review_body'] as textual feature \n",
      "  Projecting data to the feature and label columns ['total_votes', 'category', 'product_id', 'customer_id', 'text', 'is_helpful', 'review_date']\n",
      "  Data preparation - temporal train/test split based on date 2013-12-10\n",
      "  Feature encoding - Setting up feature transformations\n",
      "  Modeling - defining a logistic regression model\n",
      "---------------------------------------------------------------------\n",
      "Train accuracy 0.8677839851024208\n",
      "Test accuracy 0.8813450628956672\n",
      "Equal opportunity w.r.t. third party reviews 0.0\n",
      "# Number of ratings used 33294\n",
      "# Number of products used 3919\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Executing pipeline with seed 91011\n",
      "---------------------------------------------------------------------\n",
      "  Data access - Loading all four input relations from github\n",
      "  Data Integration - Dropping reviews written before 2011-05-22\n",
      "  Data Integration - restricting products to the following categories ['Digital_Software', 'Digital_Video_Games']\n",
      "  Data Integration - joined reviews, ratings, products & categories\n",
      "  Data preparation - using columns ['review_body'] as textual feature \n",
      "  Projecting data to the feature and label columns ['star_rating', 'total_votes', 'customer_id', 'category', 'product_id', 'text', 'is_helpful', 'review_date']\n",
      "  Data preparation - temporal train/test split based on date 2013-12-15\n",
      "  Feature encoding - Setting up feature transformations\n",
      "  Modeling - defining a logistic regression model\n",
      "---------------------------------------------------------------------\n",
      "Train accuracy 0.8576596632809239\n",
      "Test accuracy 0.8782249400875961\n",
      "Equal opportunity w.r.t. third party reviews 0.0\n",
      "# Number of ratings used 35935\n",
      "# Number of products used 4188\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Executing pipeline with seed 121314\n",
      "---------------------------------------------------------------------\n",
      "  Data access - Loading all four input relations from github\n",
      "  Data Integration - Dropping reviews written before 2012-11-26\n",
      "  Data Integration - restricting products to the following categories ['Digital_Video_Games']\n",
      "  Data Integration - joined reviews, ratings, products & categories\n",
      "  Data preparation - using columns ['review_body'] as textual feature \n",
      "  Projecting data to the feature and label columns ['total_votes', 'star_rating', 'category', 'customer_id', 'vine', 'text', 'is_helpful', 'review_date']\n",
      "  Data preparation - temporal train/test split based on date 2014-04-29\n",
      "  Feature encoding - Setting up feature transformations\n",
      "  Modeling - defining a logistic regression model\n",
      "---------------------------------------------------------------------\n",
      "Train accuracy 0.8525379626393258\n",
      "Test accuracy 0.8822315825668358\n",
      "Equal opportunity w.r.t. third party reviews 0.0\n",
      "# Number of ratings used 25749\n",
      "# Number of products used 3296\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Executing pipeline with seed 151617\n",
      "---------------------------------------------------------------------\n",
      "  Data access - Loading all four input relations from github\n",
      "  Data Integration - Dropping reviews written before 2011-10-26\n",
      "  Data Integration - restricting products to the following categories ['Digital_Software', 'Digital_Video_Games']\n",
      "  Data Integration - joined reviews, ratings, products & categories\n",
      "  Data preparation - using columns ['review_body' 'product_title' 'review_headline'] as textual feature \n",
      "  Projecting data to the feature and label columns ['star_rating', 'total_votes', 'vine', 'category', 'text', 'is_helpful', 'review_date']\n",
      "  Data preparation - temporal train/test split based on date 2014-06-26\n",
      "  Feature encoding - Setting up feature transformations\n",
      "  Modeling - defining a logistic regression model\n",
      "---------------------------------------------------------------------\n",
      "Train accuracy 0.8688361978520879\n",
      "Test accuracy 0.881930208996018\n",
      "Equal opportunity w.r.t. third party reviews 0.0\n",
      "# Number of ratings used 52423\n",
      "# Number of products used 5090\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds_to_evaluate = [1234, 5678, 91011, 121314, 151617]\n",
    "for seed in seeds_to_evaluate:\n",
    "  execute_pipeline(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1652879755927,
     "user": {
      "displayName": "Shubha Guha",
      "userId": "03778871276352105153"
     },
     "user_tz": -120
    },
    "id": "bGlcXWEfO_Sk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of freamon-user-study.ipynb",
   "provenance": [
    {
     "file_id": "1aJGpr33V318rDzXKWW5pqkoIXwXOlQmL",
     "timestamp": 1652875318647
    },
    {
     "file_id": "1Kk4BTmRcgNffNSJrE3Hv6hIMvm03jRaZ",
     "timestamp": 1652873017120
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
